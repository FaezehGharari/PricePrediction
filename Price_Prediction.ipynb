{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sea\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression,RANSACRegressor,ElasticNet\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler,PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,BaggingRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Loading file \n",
    "data = pd.read_excel('_1.xlsx')\n",
    "data.columns = ['day','month','year','store_num','buy_freq','sell_freq','price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extracting Train and Test Indices\n",
    "test_indices = list(np.where(data['price']==u'\\u061f')[0])\n",
    "data_index = list(data.index)\n",
    "train_indices = [i for i in data_index if i not in test_indices]\n",
    "train_data = data.iloc[train_indices]\n",
    "test_data = data .iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Store ID Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average : 111.479323308\n",
      "Standard Deviation : 87.5949835974\n",
      "Maximum Length : 274\n",
      "Minimum Length : 1\n"
     ]
    }
   ],
   "source": [
    "## Exraxting All Unique Store IDs\n",
    "all_stores = np.unique(train_data['store_num'].values)\n",
    "\n",
    "## Extracting data rows for each Store ID(as a look_up table(dictionary))\n",
    "data_per_store = {}\n",
    "for store in all_stores:\n",
    "    data_per_store['{}'.format(store)] = train_data[train_data['store_num'] == store]\n",
    "\n",
    "## Producing Statistics about data rows for each Store(We Want to test whether we can create \n",
    "## model per Store ID.)\n",
    "store_data_length = []\n",
    "for i in data_per_store.values():\n",
    "    store_data_length.append(len(i))\n",
    "print \"Average : {}\".format(np.mean(store_data_length))\n",
    "print \"Standard Deviation : {}\".format(np.std(store_data_length))\n",
    "print \"Maximum Length : {}\".format(np.max(store_data_length))\n",
    "print \"Minimum Length : {}\".format(np.min(store_data_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Stores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_list = []\n",
    "cols_for_clustering = ['price_diff_sign','but_to_sell_sign']\n",
    "new_data_per_store = {}\n",
    "store_cluster_lookup_table = {}\n",
    "for key in data_per_store.keys():\n",
    "    if len(data_per_store[key]) > 3:\n",
    "        sd = data_per_store[key]\n",
    "        new_representation = pd.DataFrame(sd.index)\n",
    "        buy_f = np.array([float(i) for i in sd['buy_freq'].values])\n",
    "        sell_f = np.array([float(i) for i in sd['sell_freq'].values])\n",
    "        new_representation['but_to_sell'] = buy_f / sell_f\n",
    "        new_representation['price_diff'] = sd['price'].diff().values\n",
    "        new_representation['price_diff_sign'] = np.sign(new_representation['price_diff'].dropna())\n",
    "        signs = []\n",
    "        for i in new_representation['but_to_sell'].values:\n",
    "            if i < 1 :\n",
    "                signs.append(-1)\n",
    "            elif i > 1 :\n",
    "                signs.append(1)\n",
    "            else:\n",
    "                signs.append(0)\n",
    "        new_representation['but_to_sell_sign'] = signs\n",
    "        del new_representation['but_to_sell']\n",
    "        del new_representation['price_diff']\n",
    "        new_data_per_store[key] = new_representation.dropna()\n",
    "        db = DBSCAN()\n",
    "        db.fit(new_data_per_store[key][cols_for_clustering])\n",
    "        common_list.append(collections.Counter(db.labels_).most_common())\n",
    "        store_cluster_lookup_table[key] = collections.Counter(db.labels_).most_common()[0][0]\n",
    "    else:\n",
    "        store_cluster_lookup_table[key] = -1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 208), (1, 99), (2, 83), (-1, 81), (3, 30), (-1000, 19), (4, 10), (5, 2)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(store_cluster_lookup_table.values()).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data According to Store Cluster value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster0 = []\n",
    "cluster1 = []\n",
    "cluster2 = []\n",
    "cluster3 = []\n",
    "cluster4 = []\n",
    "cluster5 = []\n",
    "cluster_minus_one =[]\n",
    "cluster_tiny_stores = []\n",
    "for i in range(len(train_data) - 1):\n",
    "    if store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == 0:\n",
    "        cluster0.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == 1:\n",
    "        cluster1.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == 2:\n",
    "        cluster2.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == 3:\n",
    "        cluster3.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == 4:\n",
    "        cluster4.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == 5:\n",
    "        cluster5.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == -1:\n",
    "        cluster_minus_one.append(train_data.iloc[i])\n",
    "    elif store_cluster_lookup_table[str(train_data.iloc[i]['store_num'])] == -1000:\n",
    "        cluster_tiny_stores.append(train_data.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster0 = pd.DataFrame(cluster0)\n",
    "cluster1 = pd.DataFrame(cluster1)\n",
    "cluster2 = pd.DataFrame(cluster2)\n",
    "cluster3 = pd.DataFrame(cluster3)\n",
    "cluster4 = pd.DataFrame(cluster4)\n",
    "cluster5 = pd.DataFrame(cluster5)\n",
    "cluster_minus_one = pd.DataFrame(cluster_minus_one)\n",
    "cluster_tiny_stores = pd.DataFrame(cluster_tiny_stores)\n",
    "clustered_data = [cluster0,cluster1,cluster2,cluster3,cluster4,cluster5,cluster_minus_one,cluster_tiny_stores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:583: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:646: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Statistics for SVR with rbf kernel\n",
    "## Random Forest Regression\n",
    "idx = [4,5] \n",
    "X = cluster2.iloc[:,idx].values\n",
    "y = cluster2.iloc[:,6].values\n",
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "param_grid = {'learning_rate' : [0.1,0.05,0.02,0.01],\n",
    "              'max_depth' : [4,6],\n",
    "              'min_samples_leaf' : [3,5,9,17],\n",
    "              'max_features' : [1.0,0.3,0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators':1000,'learning_rate': 0.05,\n",
    " 'max_depth': 4,\n",
    " 'max_features': 0.1,\n",
    " 'min_samples_leaf': 5}\n",
    "est = GradientBoostingRegressor(**params)\n",
    "est.fit(X_train,y_train)\n",
    "y_train_pred = est.predict(X_train)\n",
    "y_test_pred = est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.775, test: 0.942\n",
      "R^2 train: 0.226, test: 0.050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.38226713440180426"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred),\n",
    "                                       mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),\n",
    "                                       r2_score(y_test, y_test_pred)))\n",
    "np.mean(np.abs(y_test - y_test_pred) / y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f7db004a610>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "# compute test set deviance\n",
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "\n",
    "for i, y_pred in enumerate(lr.staged_predict(X_test)):\n",
    "    test_score[i] = lr.loss_(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, lr.train_score_, 'b-',\n",
    "         label='Training Set Deviance')\n",
    "plt.plot(np.arange(params['n_estimators']) + 1, test_score, 'r-',\n",
    "         label='Test Set Deviance')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "feature_importance = lr.feature_importances_\n",
    "# make importances relative to max importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, idx)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Based on Only information from stores itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store_standalone_data = data_per_store[data_per_store.keys()[3]]\n",
    "idx = [4,5] \n",
    "X = store_standalone_data.iloc[:,idx].values\n",
    "y = store_standalone_data.iloc[:,6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Random Forest Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=1)\n",
    "forest = RandomForestRegressor(n_estimators=1000,criterion='mse',random_state=1,n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "y_train_pred = forest.predict(X_train)\n",
    "y_test_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 29177650.595, test: 91680035.901\n",
      "R^2 train: 0.800, test: 0.395\n"
     ]
    }
   ],
   "source": [
    "print('MSE train: %.3f, test: %.3f' % (mean_squared_error(y_train, y_train_pred),\n",
    "                                       mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),\n",
    "                                       r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explotary Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Visiualizing Data Field to see whether there is some kind of linear or non-linear relationship \n",
    "## between them\n",
    "import seaborn as sea\n",
    "sea.set(style='whitegrid',context='notebook')\n",
    "## Extracting Colums ['store_num', 'buy_freq', 'sell_freq', 'price']\n",
    "cols = list(data.columns)[3:]\n",
    "sea.pairplot(train_data[cols],size=2.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between price and other Features\n",
      "Sell_freq :(0.0077505875271176661, 0.059094267647188836)\n",
      "Buy_freq :(0.0025150212459648037, 0.54022558300946044)\n",
      "Store Number :(0.044879277845874699, 7.8629068029899904e-28)\n",
      "Day :(0.0031868214706579487, 0.43770579269211296)\n",
      "Month :(0.084846501929298587, 3.4933203887432922e-95)\n",
      "Year :(0.44619258678578994, 0.0)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "The Pearson correlation coefficient measures the linear relationship between two datasets. \n",
    "Strictly speaking,Pearson's correlation requires that each dataset be normally distributed.\n",
    "Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation.\n",
    "Correlations of -1 or +1 imply an exact linear relationship.Positive correlations imply that as x \n",
    "increases, so does y. Negative correlations imply that as x increases, y decreases.\n",
    "The p-value roughly indicates the probability of an uncorrelated system producing datasets\n",
    "that have a Pearson correlation at least as extreme as the one computed from these datasets. \n",
    "The p-values are not entirely reliable but\n",
    "are probably reasonable for datasets larger than 500 or so\n",
    "\n",
    "'''\n",
    "\n",
    "print \"Pearson Correlation between price and other Features\"\n",
    "print \"Sell_freq :\" + str(pearsonr(train_data['sell_freq'],train_data['price']))\n",
    "print \"Buy_freq :\" + str(pearsonr(train_data['buy_freq'],train_data['price']))\n",
    "print \"Store Number :\" + str(pearsonr(train_data['store_num'],train_data['price']))\n",
    "print \"Day :\" + str(pearsonr(train_data['day'],train_data['price']))\n",
    "print \"Month :\" + str(pearsonr(train_data['month'],train_data['price']))\n",
    "print \"Year :\" + str(pearsonr(train_data['year'],train_data['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Normalizing Buy and Sell features(Just Two of them)\n",
    "'''\n",
    "x_std_scaler = StandardScaler()\n",
    "y_std_scaler = StandardScaler()\n",
    "X = x_std_scaler.fit_transform(train_data[train_data.columns[4:6]].values)\n",
    "y = y_std_scaler.fit_transform(train_data['price'].values)\n",
    "'''\n",
    "## Normalizing Buy and Sell features between zero and one\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(train_data[train_data.columns[4:6]].values)\n",
    "y = scaler.fit_transform(train_data['price'].values)\n",
    "X = train_data[train_data.columns[4:6]].values\n",
    "y = train_data['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59307, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr.predict(train_data[train_data.columns[4:6]].head().values)\n",
    "\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "cubic = PolynomialFeatures(degree=3)\n",
    "X_quad = quadratic.fit_transform(X_train)\n",
    "X_cubic = cubic.fit_transform(X_train)\n",
    "lr.fit(X_quad,y_train)\n",
    "lr.fit(X_cubic,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Anti-Noise Linear Regression\n",
    "ransac = RANSACRegressor(LinearRegression(),max_trials=100,min_samples=50,\n",
    "                        residual_metric=lambda x: np.sum(np.abs(x), axis=1),\n",
    "                        residual_threshold=5.0,\n",
    "                        random_state=0)\n",
    "ransac.fit(X_train,y_train)\n",
    "y_train_pred = ransac.predict(X_train)\n",
    "y_test_pred = ransac.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 958474444351.260, test: 316541156.230\n",
      "R^2 train: -4729.600, test: -0.539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print('MSE train: %.3f, test: %.3f' % ( mean_squared_error(y_train, y_train_pred), \n",
    "                                       mean_squared_error(y_test, y_test_pred)))\n",
    "from sklearn.metrics import r2_score\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred), r2_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on whole data(Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['buy_freq','sell_freq']\n",
    "benchmark = test_data[(test_data['day']== 9) & (test_data['month'] == 2) & (test_data['year'] == 2014)][cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Random Forest Regression\n",
    "idx = [4,5] \n",
    "X = train_data.iloc[:,idx].values\n",
    "y = train_data.iloc[:,6].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=1)\n",
    "forest = RandomForestRegressor(n_estimators=1000,criterion='mse',random_state=1,n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "y_train_pred = forest.predict(X_train)\n",
    "y_test_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 5695.854, test: 12425.378\n",
      "R^2 train: 0.735, test: -0.115\n",
      "0.0333183488484\n"
     ]
    }
   ],
   "source": [
    "#Statistics for RandomForest Regressor\n",
    "print('MSE train: %.3f, test: %.3f' % (mean_absolute_error(y_train, y_train_pred),\n",
    "                                       mean_absolute_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (r2_score(y_train, y_train_pred),\n",
    "                                       r2_score(y_test, y_test_pred)))\n",
    "print np.mean(np.abs(y_test - y_test_pred) / y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = forest.predict(benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373260.52799999999"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>store_num</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>sell_freq</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54175</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134455</td>\n",
       "      <td>875500</td>\n",
       "      <td>515000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54176</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137415</td>\n",
       "      <td>412000</td>\n",
       "      <td>51500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54177</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135725</td>\n",
       "      <td>10300000</td>\n",
       "      <td>5963700</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54178</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136655</td>\n",
       "      <td>20661800</td>\n",
       "      <td>103000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54179</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>139075</td>\n",
       "      <td>30900</td>\n",
       "      <td>87550</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54180</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>133585</td>\n",
       "      <td>30900</td>\n",
       "      <td>515000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54181</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134745</td>\n",
       "      <td>566500</td>\n",
       "      <td>861595</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54182</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135385</td>\n",
       "      <td>61800</td>\n",
       "      <td>227012</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54183</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136065</td>\n",
       "      <td>5994600</td>\n",
       "      <td>7899070</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54184</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>146675</td>\n",
       "      <td>93031145</td>\n",
       "      <td>93031145</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54185</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>133725</td>\n",
       "      <td>5150000</td>\n",
       "      <td>468650</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54186</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135275</td>\n",
       "      <td>150586</td>\n",
       "      <td>182310</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54187</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134085</td>\n",
       "      <td>30900</td>\n",
       "      <td>30900</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54188</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>138925</td>\n",
       "      <td>3090000</td>\n",
       "      <td>2997300</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54189</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137675</td>\n",
       "      <td>162006228</td>\n",
       "      <td>162006228</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54190</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135775</td>\n",
       "      <td>2060000</td>\n",
       "      <td>2420500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54191</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134075</td>\n",
       "      <td>56650</td>\n",
       "      <td>51500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54192</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>138095</td>\n",
       "      <td>144200</td>\n",
       "      <td>206000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54193</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137685</td>\n",
       "      <td>6088948</td>\n",
       "      <td>18596238</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54194</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>146045</td>\n",
       "      <td>236900</td>\n",
       "      <td>236900</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54195</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>146295</td>\n",
       "      <td>56650</td>\n",
       "      <td>1009400</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54196</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135955</td>\n",
       "      <td>103000</td>\n",
       "      <td>721000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54197</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137035</td>\n",
       "      <td>1585582</td>\n",
       "      <td>2139619</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54198</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>145445</td>\n",
       "      <td>10926240</td>\n",
       "      <td>16076240</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54199</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136775</td>\n",
       "      <td>4064998</td>\n",
       "      <td>3807086</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54200</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136025</td>\n",
       "      <td>12360000</td>\n",
       "      <td>1735550</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54201</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134515</td>\n",
       "      <td>4913100</td>\n",
       "      <td>3106480</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54202</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>133685</td>\n",
       "      <td>1225700</td>\n",
       "      <td>3038500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54203</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135105</td>\n",
       "      <td>1740700</td>\n",
       "      <td>1184500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54204</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>133595</td>\n",
       "      <td>61964800</td>\n",
       "      <td>70070900</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54371</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136145</td>\n",
       "      <td>15450000</td>\n",
       "      <td>751900</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54372</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137395</td>\n",
       "      <td>618000</td>\n",
       "      <td>706580</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54373</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136185</td>\n",
       "      <td>237827</td>\n",
       "      <td>54899</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54374</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>138035</td>\n",
       "      <td>5150000</td>\n",
       "      <td>5304500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54375</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134645</td>\n",
       "      <td>710494</td>\n",
       "      <td>835330</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54376</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135545</td>\n",
       "      <td>39363304</td>\n",
       "      <td>69096932</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54377</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>144815</td>\n",
       "      <td>1060900</td>\n",
       "      <td>1288015</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54378</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135865</td>\n",
       "      <td>15450000</td>\n",
       "      <td>15450000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54379</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135225</td>\n",
       "      <td>1627400</td>\n",
       "      <td>1854000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54380</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135085</td>\n",
       "      <td>104648</td>\n",
       "      <td>20600</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54381</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135075</td>\n",
       "      <td>625210</td>\n",
       "      <td>1601650</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54382</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137125</td>\n",
       "      <td>20176979</td>\n",
       "      <td>15458961</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54383</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>138825</td>\n",
       "      <td>5150000</td>\n",
       "      <td>4784350</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54384</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>145355</td>\n",
       "      <td>257500</td>\n",
       "      <td>463500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54385</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>133765</td>\n",
       "      <td>803400</td>\n",
       "      <td>757050</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54386</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137215</td>\n",
       "      <td>691130</td>\n",
       "      <td>154500</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54387</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>144975</td>\n",
       "      <td>15450000</td>\n",
       "      <td>15450000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54388</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135415</td>\n",
       "      <td>2575000</td>\n",
       "      <td>2266000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54389</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>145695</td>\n",
       "      <td>10300000</td>\n",
       "      <td>10403000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54390</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>176215</td>\n",
       "      <td>15450000</td>\n",
       "      <td>10300000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54391</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>138955</td>\n",
       "      <td>269860</td>\n",
       "      <td>221450</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54392</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>145465</td>\n",
       "      <td>991581</td>\n",
       "      <td>6979280</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54393</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134265</td>\n",
       "      <td>5791793</td>\n",
       "      <td>6046203</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54394</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>139345</td>\n",
       "      <td>10300</td>\n",
       "      <td>133900</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54395</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135245</td>\n",
       "      <td>599460</td>\n",
       "      <td>82400</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54396</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>135475</td>\n",
       "      <td>123600</td>\n",
       "      <td>309000</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54397</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>137085</td>\n",
       "      <td>736450</td>\n",
       "      <td>2868550</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54398</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>145135</td>\n",
       "      <td>43358880</td>\n",
       "      <td>60971880</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54399</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>136835</td>\n",
       "      <td>127720</td>\n",
       "      <td>33990</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54400</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>134985</td>\n",
       "      <td>200850</td>\n",
       "      <td>175100</td>\n",
       "      <td>379080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>226 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       day  month  year  store_num   buy_freq  sell_freq   price\n",
       "54175   10      2  2014     134455     875500     515000  379080\n",
       "54176   10      2  2014     137415     412000      51500  379080\n",
       "54177   10      2  2014     135725   10300000    5963700  379080\n",
       "54178   10      2  2014     136655   20661800     103000  379080\n",
       "54179   10      2  2014     139075      30900      87550  379080\n",
       "54180   10      2  2014     133585      30900     515000  379080\n",
       "54181   10      2  2014     134745     566500     861595  379080\n",
       "54182   10      2  2014     135385      61800     227012  379080\n",
       "54183   10      2  2014     136065    5994600    7899070  379080\n",
       "54184   10      2  2014     146675   93031145   93031145  379080\n",
       "54185   10      2  2014     133725    5150000     468650  379080\n",
       "54186   10      2  2014     135275     150586     182310  379080\n",
       "54187   10      2  2014     134085      30900      30900  379080\n",
       "54188   10      2  2014     138925    3090000    2997300  379080\n",
       "54189   10      2  2014     137675  162006228  162006228  379080\n",
       "54190   10      2  2014     135775    2060000    2420500  379080\n",
       "54191   10      2  2014     134075      56650      51500  379080\n",
       "54192   10      2  2014     138095     144200     206000  379080\n",
       "54193   10      2  2014     137685    6088948   18596238  379080\n",
       "54194   10      2  2014     146045     236900     236900  379080\n",
       "54195   10      2  2014     146295      56650    1009400  379080\n",
       "54196   10      2  2014     135955     103000     721000  379080\n",
       "54197   10      2  2014     137035    1585582    2139619  379080\n",
       "54198   10      2  2014     145445   10926240   16076240  379080\n",
       "54199   10      2  2014     136775    4064998    3807086  379080\n",
       "54200   10      2  2014     136025   12360000    1735550  379080\n",
       "54201   10      2  2014     134515    4913100    3106480  379080\n",
       "54202   10      2  2014     133685    1225700    3038500  379080\n",
       "54203   10      2  2014     135105    1740700    1184500  379080\n",
       "54204   10      2  2014     133595   61964800   70070900  379080\n",
       "...    ...    ...   ...        ...        ...        ...     ...\n",
       "54371   10      2  2014     136145   15450000     751900  379080\n",
       "54372   10      2  2014     137395     618000     706580  379080\n",
       "54373   10      2  2014     136185     237827      54899  379080\n",
       "54374   10      2  2014     138035    5150000    5304500  379080\n",
       "54375   10      2  2014     134645     710494     835330  379080\n",
       "54376   10      2  2014     135545   39363304   69096932  379080\n",
       "54377   10      2  2014     144815    1060900    1288015  379080\n",
       "54378   10      2  2014     135865   15450000   15450000  379080\n",
       "54379   10      2  2014     135225    1627400    1854000  379080\n",
       "54380   10      2  2014     135085     104648      20600  379080\n",
       "54381   10      2  2014     135075     625210    1601650  379080\n",
       "54382   10      2  2014     137125   20176979   15458961  379080\n",
       "54383   10      2  2014     138825    5150000    4784350  379080\n",
       "54384   10      2  2014     145355     257500     463500  379080\n",
       "54385   10      2  2014     133765     803400     757050  379080\n",
       "54386   10      2  2014     137215     691130     154500  379080\n",
       "54387   10      2  2014     144975   15450000   15450000  379080\n",
       "54388   10      2  2014     135415    2575000    2266000  379080\n",
       "54389   10      2  2014     145695   10300000   10403000  379080\n",
       "54390   10      2  2014     176215   15450000   10300000  379080\n",
       "54391   10      2  2014     138955     269860     221450  379080\n",
       "54392   10      2  2014     145465     991581    6979280  379080\n",
       "54393   10      2  2014     134265    5791793    6046203  379080\n",
       "54394   10      2  2014     139345      10300     133900  379080\n",
       "54395   10      2  2014     135245     599460      82400  379080\n",
       "54396   10      2  2014     135475     123600     309000  379080\n",
       "54397   10      2  2014     137085     736450    2868550  379080\n",
       "54398   10      2  2014     145135   43358880   60971880  379080\n",
       "54399   10      2  2014     136835     127720      33990  379080\n",
       "54400   10      2  2014     134985     200850     175100  379080\n",
       "\n",
       "[226 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[(train_data['day']== 10) & (train_data['month'] == 2) & (train_data['year'] == 2014)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boost_clf = GradientBoostingRegressor(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:324: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/home/user/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/data.py:359: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "## Statistics for SVR with rbf kernel\n",
    "## Random Forest Regression\n",
    "idx = [4,5] \n",
    "X = train_data.iloc[:,idx].values\n",
    "y = train_data.iloc[:,6].values\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, init=None, learning_rate=0.1, loss='ls',\n",
       "             max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "             presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boost_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
